{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gamQKLOASgWg"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/crunchdao/adialab-notebooks/blob/main/quickstarter_notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMM_vmu2SgWn"
   },
   "source": [
    "# ![title](./img/adialab2-min.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADIALab forecasting competition. Tutorial notebook 2\n",
    " This notebook can be viewed as a continuation of the first tutorial notebook [[url here]], where we now seek to explore the performance of a non-linear model, Light Gradient Boosting Model (LGBM), of our already prepared dataset. Similarly, the goal of this notebook is both to introduce the competitors to the exercise, as well as to suggest some directions that could be good starting points. Sugesstions here depicted are of course not a requirement and arbitrarily different directions can be pursued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6CByWNySgWp"
   },
   "source": [
    "### Preliminary step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GdzADEE0SgWp",
    "outputId": "da8ef196-270e-4a68-9dca-e6d5acb144b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crunch-cli in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (1.2.0)\n",
      "Collecting crunch-cli\n",
      "  Using cached crunch_cli-1.2.2-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: coloredlogs in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (15.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (4.64.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (2.28.1)\n",
      "Requirement already satisfied: gitignorefile in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.1.2)\n",
      "Requirement already satisfied: astor in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (0.8.1)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.2.0)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (8.1.3)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.5.2)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (5.9.4)\n",
      "Requirement already satisfied: pyarrow in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (10.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from coloredlogs->crunch-cli) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (1.24.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->crunch-cli) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for crunch-cli: [Errno 2] No such file or directory: '/home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages/crunch_cli-1.2.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: crunch-cli\n",
      "  Attempting uninstall: crunch-cli\n",
      "\u001b[33m    WARNING: No metadata found in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: crunch-cli 1.2.0\n",
      "    Can't uninstall 'crunch-cli'. No files were found to uninstall.\n",
      "Successfully installed crunch-cli-1.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "env: API_BASE_URL=https://api.adialab.crunchdao.io\n",
      "env: WEB_BASE_URL=https://adialab.crunchdao.io/\n"
     ]
    }
   ],
   "source": [
    "!pip3 install crunch-cli --upgrade\n",
    "\n",
    "%env API_BASE_URL=https://api.adialab.crunchdao.io\n",
    "%env WEB_BASE_URL=https://adialab.crunchdao.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SkK61mCbSgWr",
    "outputId": "b64fce87-7726-44f3-f6ea-d08163cd9190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded inline runner with module: <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "# import and instantiante the crunch package in this notebook\n",
    "import crunch\n",
    "crunch = crunch.load_notebook(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CQ00Mb8aSgWs",
    "outputId": "5df464aa-1ebd-445a-f7f9-08d8e0156075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: crunch-cli in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: gitignorefile in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.1.2)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.2.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (2.28.1)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (1.5.2)\n",
      "Requirement already satisfied: click in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (8.1.3)\n",
      "Requirement already satisfied: astor in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (0.8.1)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (5.9.4)\n",
      "Requirement already satisfied: coloredlogs in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (15.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (4.64.1)\n",
      "Requirement already satisfied: pyarrow in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from crunch-cli) (10.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from coloredlogs->crunch-cli) (10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from pandas->crunch-cli) (2022.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->crunch-cli) (2022.12.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->crunch-cli) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "attractive-pablo: already exists (use --force to override)\n",
      "Aborted!\n",
      "/mnt/qromatiq/Pablo/projects/CrunchDAO_Competition/attractive-pablo\n"
     ]
    }
   ],
   "source": [
    "%pip install crunch-cli --upgrade\n",
    "!crunch --notebook setup attractive-pablo --token lFzV3HOfNH3hsbfr52k2q4i3ccMerLHxbEhe5IXJrECsAQ9rGuzQKLzgQIfJjcIt\n",
    "%cd attractive-pablo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vNvaY-EqSgWs",
    "outputId": "1d4813ae-33b7-42a3-82e1-405c375012f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/qromatiq/Pablo/projects/CrunchDAO_Competition\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import snappy\n",
    "import fastparquet\n",
    "warnings.filterwarnings(\"ignore\") #This is not advised in general, but it is used in this notebook to clean the presentation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download data/X_train.parquet from https://datacrunch-com.s3.eu-west-1.amazonaws.com/staging/adia-tournament/data-releases/1/X_train.parquet\n",
      "already exists: file length match\n",
      "download data/y_train.parquet from https://datacrunch-com.s3.eu-west-1.amazonaws.com/staging/adia-tournament/data-releases/1/y_train.parquet\n",
      "already exists: file length match\n",
      "download data/X_test.parquet from https://datacrunch-com.s3.eu-west-1.amazonaws.com/staging/adia-tournament/data-releases/1/X_test_reduced.parquet\n",
      "already exists: file length match\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, y_train, X_test = crunch.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>453</th>\n",
       "      <th>454</th>\n",
       "      <th>455</th>\n",
       "      <th>456</th>\n",
       "      <th>457</th>\n",
       "      <th>458</th>\n",
       "      <th>459</th>\n",
       "      <th>460</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dae29c8061b3176b9208f26afbb96e2ca50886db41902d...</td>\n",
       "      <td>-0.909515</td>\n",
       "      <td>0.388808</td>\n",
       "      <td>-1.535913</td>\n",
       "      <td>-0.133312</td>\n",
       "      <td>-1.826404</td>\n",
       "      <td>-0.532795</td>\n",
       "      <td>0.351273</td>\n",
       "      <td>0.158866</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.731349</td>\n",
       "      <td>-0.456020</td>\n",
       "      <td>-0.257331</td>\n",
       "      <td>0.396074</td>\n",
       "      <td>0.318007</td>\n",
       "      <td>-0.538754</td>\n",
       "      <td>-0.625193</td>\n",
       "      <td>-0.753419</td>\n",
       "      <td>0.154403</td>\n",
       "      <td>1.069385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2f71f1b5d49fbd131351df95848dc91ab14662af62d4d0...</td>\n",
       "      <td>-0.107694</td>\n",
       "      <td>-0.097967</td>\n",
       "      <td>-0.539599</td>\n",
       "      <td>-0.331276</td>\n",
       "      <td>-0.942609</td>\n",
       "      <td>-0.054123</td>\n",
       "      <td>-1.212772</td>\n",
       "      <td>1.688034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610428</td>\n",
       "      <td>-0.984907</td>\n",
       "      <td>-0.429806</td>\n",
       "      <td>0.199055</td>\n",
       "      <td>0.202587</td>\n",
       "      <td>1.612578</td>\n",
       "      <td>0.302153</td>\n",
       "      <td>-0.165713</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>0.083180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b8d41ef950b69f94c380410f59f47e15666c57b74573b6...</td>\n",
       "      <td>0.092316</td>\n",
       "      <td>0.052596</td>\n",
       "      <td>-0.652025</td>\n",
       "      <td>1.218241</td>\n",
       "      <td>0.382968</td>\n",
       "      <td>-0.861838</td>\n",
       "      <td>-0.318937</td>\n",
       "      <td>-0.744261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212365</td>\n",
       "      <td>-0.046016</td>\n",
       "      <td>1.147463</td>\n",
       "      <td>0.696961</td>\n",
       "      <td>-0.574426</td>\n",
       "      <td>1.255969</td>\n",
       "      <td>0.270394</td>\n",
       "      <td>1.272939</td>\n",
       "      <td>-0.643112</td>\n",
       "      <td>0.433585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cdce060d04ce28a551eaab653cc4b01f5ad878aeb932ec...</td>\n",
       "      <td>4.119639</td>\n",
       "      <td>1.018918</td>\n",
       "      <td>3.687519</td>\n",
       "      <td>1.597563</td>\n",
       "      <td>0.055918</td>\n",
       "      <td>-1.406041</td>\n",
       "      <td>0.652994</td>\n",
       "      <td>0.251138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.254787</td>\n",
       "      <td>-1.155922</td>\n",
       "      <td>-1.108540</td>\n",
       "      <td>-2.046100</td>\n",
       "      <td>1.311100</td>\n",
       "      <td>-0.322965</td>\n",
       "      <td>0.999248</td>\n",
       "      <td>-1.238640</td>\n",
       "      <td>0.882844</td>\n",
       "      <td>-1.333590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>86f6e6d9407ad3abfab91a3bbfb7ad71553e3f968765b8...</td>\n",
       "      <td>0.109644</td>\n",
       "      <td>-0.290280</td>\n",
       "      <td>-0.278987</td>\n",
       "      <td>-0.603259</td>\n",
       "      <td>0.136952</td>\n",
       "      <td>-1.725076</td>\n",
       "      <td>-0.062219</td>\n",
       "      <td>-0.183102</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.007721</td>\n",
       "      <td>-0.482311</td>\n",
       "      <td>-0.269142</td>\n",
       "      <td>-0.899796</td>\n",
       "      <td>1.083332</td>\n",
       "      <td>0.674665</td>\n",
       "      <td>-1.095657</td>\n",
       "      <td>-0.402669</td>\n",
       "      <td>0.677189</td>\n",
       "      <td>0.319992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742665</th>\n",
       "      <td>268</td>\n",
       "      <td>5a18ddc0f252fa17cbd2a5bfe2f3786c0afb5052dd92be...</td>\n",
       "      <td>0.790984</td>\n",
       "      <td>1.560877</td>\n",
       "      <td>-0.328996</td>\n",
       "      <td>-0.190068</td>\n",
       "      <td>0.314971</td>\n",
       "      <td>-0.001609</td>\n",
       "      <td>0.313957</td>\n",
       "      <td>-0.315743</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.450422</td>\n",
       "      <td>-1.044100</td>\n",
       "      <td>0.631455</td>\n",
       "      <td>-1.322626</td>\n",
       "      <td>-0.407846</td>\n",
       "      <td>0.578026</td>\n",
       "      <td>0.830650</td>\n",
       "      <td>1.414314</td>\n",
       "      <td>-0.845734</td>\n",
       "      <td>0.399335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742666</th>\n",
       "      <td>268</td>\n",
       "      <td>73c197cf1cb75641710562fe26d4f562c8228847a67949...</td>\n",
       "      <td>-1.129492</td>\n",
       "      <td>0.696247</td>\n",
       "      <td>-1.494771</td>\n",
       "      <td>-0.404022</td>\n",
       "      <td>0.909996</td>\n",
       "      <td>-0.658659</td>\n",
       "      <td>0.688591</td>\n",
       "      <td>1.634416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475011</td>\n",
       "      <td>0.319023</td>\n",
       "      <td>-1.038112</td>\n",
       "      <td>0.222924</td>\n",
       "      <td>0.804017</td>\n",
       "      <td>-0.969177</td>\n",
       "      <td>-1.011879</td>\n",
       "      <td>-0.921781</td>\n",
       "      <td>-0.067543</td>\n",
       "      <td>0.491890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742667</th>\n",
       "      <td>268</td>\n",
       "      <td>bad7ff9ebc5579589e5ef36cb58f962c90c864fd3dfb22...</td>\n",
       "      <td>1.656413</td>\n",
       "      <td>-1.267060</td>\n",
       "      <td>0.748902</td>\n",
       "      <td>-0.196263</td>\n",
       "      <td>0.831206</td>\n",
       "      <td>-1.590837</td>\n",
       "      <td>3.079856</td>\n",
       "      <td>0.498583</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010330</td>\n",
       "      <td>-0.426130</td>\n",
       "      <td>-0.624393</td>\n",
       "      <td>-0.236483</td>\n",
       "      <td>-0.244052</td>\n",
       "      <td>1.280749</td>\n",
       "      <td>-2.001158</td>\n",
       "      <td>-1.036838</td>\n",
       "      <td>-1.959235</td>\n",
       "      <td>-2.534523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742668</th>\n",
       "      <td>268</td>\n",
       "      <td>5b968ca44ac0550be6f31470a96e572cd1c58d36cc26c7...</td>\n",
       "      <td>0.282704</td>\n",
       "      <td>0.156104</td>\n",
       "      <td>-1.165022</td>\n",
       "      <td>0.513334</td>\n",
       "      <td>-1.111948</td>\n",
       "      <td>-1.368465</td>\n",
       "      <td>-1.347184</td>\n",
       "      <td>-0.926533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411093</td>\n",
       "      <td>0.225324</td>\n",
       "      <td>-0.112838</td>\n",
       "      <td>-0.366831</td>\n",
       "      <td>-0.385833</td>\n",
       "      <td>-0.301606</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>-0.895311</td>\n",
       "      <td>-0.819201</td>\n",
       "      <td>-0.996246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742669</th>\n",
       "      <td>268</td>\n",
       "      <td>a42ec1ac915edb35b440184ca52015bf3fdba53c631b1f...</td>\n",
       "      <td>-0.813073</td>\n",
       "      <td>-0.824916</td>\n",
       "      <td>-0.368725</td>\n",
       "      <td>0.136837</td>\n",
       "      <td>0.270865</td>\n",
       "      <td>0.710876</td>\n",
       "      <td>0.734015</td>\n",
       "      <td>-1.233695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134728</td>\n",
       "      <td>0.133413</td>\n",
       "      <td>-0.904207</td>\n",
       "      <td>-0.430508</td>\n",
       "      <td>-1.598422</td>\n",
       "      <td>-0.819337</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>-0.532539</td>\n",
       "      <td>0.105044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>742670 rows × 463 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                                 id         0  \\\n",
       "0          0  dae29c8061b3176b9208f26afbb96e2ca50886db41902d... -0.909515   \n",
       "1          0  2f71f1b5d49fbd131351df95848dc91ab14662af62d4d0... -0.107694   \n",
       "2          0  b8d41ef950b69f94c380410f59f47e15666c57b74573b6...  0.092316   \n",
       "3          0  cdce060d04ce28a551eaab653cc4b01f5ad878aeb932ec...  4.119639   \n",
       "4          0  86f6e6d9407ad3abfab91a3bbfb7ad71553e3f968765b8...  0.109644   \n",
       "...      ...                                                ...       ...   \n",
       "742665   268  5a18ddc0f252fa17cbd2a5bfe2f3786c0afb5052dd92be...  0.790984   \n",
       "742666   268  73c197cf1cb75641710562fe26d4f562c8228847a67949... -1.129492   \n",
       "742667   268  bad7ff9ebc5579589e5ef36cb58f962c90c864fd3dfb22...  1.656413   \n",
       "742668   268  5b968ca44ac0550be6f31470a96e572cd1c58d36cc26c7...  0.282704   \n",
       "742669   268  a42ec1ac915edb35b440184ca52015bf3fdba53c631b1f... -0.813073   \n",
       "\n",
       "               1         2         3         4         5         6         7  \\\n",
       "0       0.388808 -1.535913 -0.133312 -1.826404 -0.532795  0.351273  0.158866   \n",
       "1      -0.097967 -0.539599 -0.331276 -0.942609 -0.054123 -1.212772  1.688034   \n",
       "2       0.052596 -0.652025  1.218241  0.382968 -0.861838 -0.318937 -0.744261   \n",
       "3       1.018918  3.687519  1.597563  0.055918 -1.406041  0.652994  0.251138   \n",
       "4      -0.290280 -0.278987 -0.603259  0.136952 -1.725076 -0.062219 -0.183102   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "742665  1.560877 -0.328996 -0.190068  0.314971 -0.001609  0.313957 -0.315743   \n",
       "742666  0.696247 -1.494771 -0.404022  0.909996 -0.658659  0.688591  1.634416   \n",
       "742667 -1.267060  0.748902 -0.196263  0.831206 -1.590837  3.079856  0.498583   \n",
       "742668  0.156104 -1.165022  0.513334 -1.111948 -1.368465 -1.347184 -0.926533   \n",
       "742669 -0.824916 -0.368725  0.136837  0.270865  0.710876  0.734015 -1.233695   \n",
       "\n",
       "        ...       451       452       453       454       455       456  \\\n",
       "0       ... -0.731349 -0.456020 -0.257331  0.396074  0.318007 -0.538754   \n",
       "1       ...  0.610428 -0.984907 -0.429806  0.199055  0.202587  1.612578   \n",
       "2       ...  0.212365 -0.046016  1.147463  0.696961 -0.574426  1.255969   \n",
       "3       ...  1.254787 -1.155922 -1.108540 -2.046100  1.311100 -0.322965   \n",
       "4       ... -2.007721 -0.482311 -0.269142 -0.899796  1.083332  0.674665   \n",
       "...     ...       ...       ...       ...       ...       ...       ...   \n",
       "742665  ... -1.450422 -1.044100  0.631455 -1.322626 -0.407846  0.578026   \n",
       "742666  ... -0.475011  0.319023 -1.038112  0.222924  0.804017 -0.969177   \n",
       "742667  ... -0.010330 -0.426130 -0.624393 -0.236483 -0.244052  1.280749   \n",
       "742668  ...  0.411093  0.225324 -0.112838 -0.366831 -0.385833 -0.301606   \n",
       "742669  ...  0.134728  0.133413 -0.904207 -0.430508 -1.598422 -0.819337   \n",
       "\n",
       "             457       458       459       460  \n",
       "0      -0.625193 -0.753419  0.154403  1.069385  \n",
       "1       0.302153 -0.165713  0.905807  0.083180  \n",
       "2       0.270394  1.272939 -0.643112  0.433585  \n",
       "3       0.999248 -1.238640  0.882844 -1.333590  \n",
       "4      -1.095657 -0.402669  0.677189  0.319992  \n",
       "...          ...       ...       ...       ...  \n",
       "742665  0.830650  1.414314 -0.845734  0.399335  \n",
       "742666 -1.011879 -0.921781 -0.067543  0.491890  \n",
       "742667 -2.001158 -1.036838 -1.959235 -2.534523  \n",
       "742668  0.395659 -0.895311 -0.819201 -0.996246  \n",
       "742669  0.012623  0.624302 -0.532539  0.105044  \n",
       "\n",
       "[742670 rows x 463 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we complete 2 tasks in order to improve the performance of Lgbm with respect to our tutorial notebook:\n",
    "1. We define a custom loss that aligns better than MSE with our optimization needs, and equip Lgbm with it\n",
    "2. We use an optimization framework called optuna to perform hyperparameter search\n",
    "3. We find a solution that is competitive with the linear model exploration of the first tutorial notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a new loss function to be defined, we are required to provide the values of the gradient and the hessian as outputs. This clearly implies the need for a differentiable loss function.\n",
    "In our case, Spearman's rank correlation is not a differentiable function (although some implementations exist, but are beyong the scope of this notebook). However, we can try to tackle this problem using at least 2 different approaches:\n",
    "\n",
    "1. Find a direct differentiable approximation of the loss.\n",
    "2. Find the a loss function that is as similar as possible to our desired rank correlation, or has desirable properties that position it as better suited than MSE.\n",
    "\n",
    "In this notebook we will choose to implement a binary cross entropy based loss function (webince). The rationale is that MSE does not distinguish between the sign of the error, just the distance to it, whereas webince takes the sign information into account, potentially resulting in better correlation scores. In our implementation we can find an expression for its first and second derivate at each sample. Then it can be fed directly into our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webince(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    labels = (labels + 1)/2\n",
    "    preds = 1. / (1. + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1. - preds)\n",
    "    return grad, hess\n",
    "\n",
    "def SpearmanCorr(y_true, y_pred):\n",
    "    return pd.Series(y_true).corr(pd.Series(y_pred), method='spearman')\n",
    "\n",
    "\n",
    "def get_rank_corr_score(y_preds,y_trues):\n",
    "    rank_pred = y_preds.groupby('date',group_keys=True).apply(lambda x: x.rank(pct=True, method=\"first\"))    \n",
    "    correlation_score = np.corrcoef(rank_pred['y'],y_trues['y'])[0,1]\n",
    "    return correlation_score\n",
    "\n",
    "def lgbm_correlation(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'Correlation', SpearmanCorr(labels,preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-12 12:53:42,159]\u001b[0m A new study created in memory with name: no-name-bbe0879f-c23c-4780-92c5-64007deab7ce\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's Correlation: 0.0458927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's Correlation: 0.0414709\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's Correlation: 0.0595078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's Correlation: 0.0394448\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's Correlation: 0.0420039\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's Correlation: 0.0291271\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's Correlation: 0.0406074\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's Correlation: 0.0216931\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's Correlation: 0.0337865\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's Correlation: 0.0296822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-12 12:55:42,237]\u001b[0m Trial 0 finished with value: 0.03830193977546721 and parameters: {'learning_rate': 0.22376680361634, 'lambda_l1': 0.043264664415812004, 'lambda_l2': 0.26793818570368366, 'num_leaves': 122, 'feature_fraction': 0.552666509101743, 'bagging_fraction': 0.11159660652286685, 'min_child_samples': 4593}. Best is trial 0 with value: 0.03830193977546721.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float('learning_rate',0.00001,1)\n",
    "    lambda_l1 = trial.suggest_float('lambda_l1',0,1)\n",
    "    lambda_l2 = trial.suggest_float('lambda_l2',0,1)\n",
    "    num_leaves = trial.suggest_int('num_leaves',2,130)\n",
    "    feature_fraction = trial.suggest_float('feature_fraction',0,1)\n",
    "    bagging_fraction = trial.suggest_float('bagging_fraction',0,1)\n",
    "    min_child_samples = trial.suggest_int('min_child_samples',1,10000)\n",
    "\n",
    "    param = {'objective': 'none',\n",
    "         'metric': 'none',\n",
    "         'learning_rate': learning_rate,\n",
    "         'lambda_l1': lambda_l1,\n",
    "         'lambda_l2': lambda_l2,\n",
    "         'num_leaves': num_leaves,\n",
    "         'feature_fraction': feature_fraction,\n",
    "         'bagging_fraction': bagging_fraction,\n",
    "         'min_child_samples': min_child_samples,\n",
    "         'verbose':-1}\n",
    "\n",
    "    lgb_perf = []\n",
    "    X = np.array(list(range(np.max(X_train['date']))))\n",
    "    tscv = TimeSeriesSplit(n_splits=10)\n",
    "    for train, test in tscv.split(X):\n",
    "        fold_train_X = X_train.loc[np.logical_and(X_train['date'] >= train[0], X_train['date'] <= (train[-3])),:] # 2 dates gap\n",
    "        fold_train_y = y_train.loc[np.logical_and(y_train['date'] >= train[0], y_train['date'] <= (train[-3])),:]\n",
    "        fold_test_X = X_train.loc[np.logical_and(X_train['date'] >= test[0], X_train['date'] <= test[-1]),:]\n",
    "        fold_test_y = y_train.loc[np.logical_and(y_train['date'] >= test[0], y_train['date'] <= test[-1]),:]\n",
    "\n",
    "\n",
    "        dtrain = lgb.Dataset(fold_train_X.iloc[:,2:], fold_train_y['y'])\n",
    "        dval = lgb.Dataset(fold_test_X.iloc[:,2:], fold_test_y['y'])\n",
    "        \n",
    "        \n",
    "        clf = lgb.train(param,dtrain,valid_sets=dval,verbose_eval=-1,early_stopping_rounds=100,\n",
    "                        num_boost_round=2000,fobj=webince,feval=lgbm_correlation)\n",
    "        preds = clf.predict(fold_test_X.iloc[:,2:])\n",
    "        preds = pd.DataFrame(preds,columns=['y'])\n",
    "        preds['date'] = np.array(fold_test_X['date'])\n",
    "        score = get_rank_corr_score(preds,fold_test_y)  \n",
    "        lgb_perf.append(score) \n",
    "    return np.mean(lgb_perf)    \n",
    "    \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=1)\n",
    "#N_hours =2 #We ran the study for 2 hours\n",
    "#study.optimize(objective, timeout=int(3600*(N_hours))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_value,'\\n')#print parameter values\n",
    "display(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)#see a graphical plot of the study optimization trajectory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "0494ab8644d1e8ef778e02480acc7da2282f44e80ecbebb91281925bda237217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
